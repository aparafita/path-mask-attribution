{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from notmnist_cnn import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_CUDA = False\n",
    "\n",
    "if not DISABLE_CUDA and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NotMNIST(\n",
    "    os.path.join(*'data/notMNIST_small'.split('/')),\n",
    "    batch_size=32, test_size=.2, val_size=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def notmnist_model():\n",
    "    feature_model = nn.Sequential( # 1, 28, 28\n",
    "        OrderedDict([\n",
    "            ('conv1', nn.Conv2d(1, 16, kernel_size=5, stride=3, padding=2, bias=False)), # 16, 10, 10\n",
    "            ('conv1_bn', nn.BatchNorm2d(16)),\n",
    "            ('conv1_relu', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(16, 32, kernel_size=3, stride=1, bias=False)), # 32, 8, 8\n",
    "            ('conv2_bn', nn.BatchNorm2d(32)),\n",
    "            ('conv2_relu', nn.ReLU()),\n",
    "            ('conv3', nn.Conv2d(32, 64, kernel_size=3, stride=1, bias=False)), # 64, 6, 6\n",
    "            ('conv3_bn', nn.BatchNorm2d(64)),\n",
    "            ('conv3_relu', nn.ReLU())\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    classifier_model = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('dense1', nn.Linear(64 * 6 * 6, 128, bias=False)),\n",
    "            ('dense1_bn', nn.BatchNorm1d(128)),\n",
    "            ('dense1_relu', nn.ReLU()),\n",
    "            ('dense1_dropout', nn.Dropout()),\n",
    "            ('output', nn.Linear(128, 10)),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('features', feature_model),\n",
    "            ('flatten', Flatten()),\n",
    "            ('classifier', classifier_model)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train_loss = 229.490, train_accuracy = 0.857, val_loss = 26.148, val_accuracy = 0.916\n",
      "Epoch 02: train_loss = 102.019, train_accuracy = 0.922, val_loss = 21.568, val_accuracy = 0.930\n",
      "Epoch 03: train_loss = 80.260, train_accuracy = 0.937, val_loss = 21.691, val_accuracy = 0.928\n",
      "Epoch 04: train_loss = 66.447, train_accuracy = 0.946, val_loss = 20.980, val_accuracy = 0.929\n",
      "Epoch 05: train_loss = 55.301, train_accuracy = 0.955, val_loss = 20.394, val_accuracy = 0.933\n",
      "Epoch 06: train_loss = 46.762, train_accuracy = 0.961, val_loss = 19.379, val_accuracy = 0.939\n",
      "Epoch 07: train_loss = 37.672, train_accuracy = 0.969, val_loss = 20.820, val_accuracy = 0.939\n",
      "Epoch 08: train_loss = 34.497, train_accuracy = 0.970, val_loss = 23.180, val_accuracy = 0.933\n",
      "Epoch 09: train_loss = 29.589, train_accuracy = 0.975, val_loss = 22.390, val_accuracy = 0.936\n",
      "Epoch 10: train_loss = 27.274, train_accuracy = 0.977, val_loss = 23.195, val_accuracy = 0.936\n",
      "Epoch 11: train_loss = 23.898, train_accuracy = 0.980, val_loss = 22.756, val_accuracy = 0.941\n",
      "Epoch 12: train_loss = 20.174, train_accuracy = 0.982, val_loss = 24.535, val_accuracy = 0.937\n",
      "Epoch 13: train_loss = 19.266, train_accuracy = 0.984, val_loss = 27.219, val_accuracy = 0.934\n",
      "Epoch 14: train_loss = 17.434, train_accuracy = 0.986, val_loss = 25.354, val_accuracy = 0.935\n",
      "Epoch 15: train_loss = 17.241, train_accuracy = 0.984, val_loss = 29.202, val_accuracy = 0.933\n",
      "Epoch 16: train_loss = 17.529, train_accuracy = 0.985, val_loss = 26.146, val_accuracy = 0.936\n",
      "Epoch 17: train_loss = 12.640, train_accuracy = 0.989, val_loss = 26.069, val_accuracy = 0.935\n",
      "Epoch 18: train_loss = 13.885, train_accuracy = 0.988, val_loss = 27.365, val_accuracy = 0.936\n",
      "Epoch 19: train_loss = 12.755, train_accuracy = 0.989, val_loss = 28.047, val_accuracy = 0.935\n",
      "Epoch 20: train_loss = 12.120, train_accuracy = 0.990, val_loss = 29.182, val_accuracy = 0.937\n",
      "Epoch 21: train_loss = 13.073, train_accuracy = 0.989, val_loss = 31.404, val_accuracy = 0.934\n",
      "Epoch 22: train_loss = 11.028, train_accuracy = 0.990, val_loss = 30.532, val_accuracy = 0.939\n",
      "Epoch 23: train_loss = 12.120, train_accuracy = 0.988, val_loss = 31.514, val_accuracy = 0.932\n",
      "Epoch 24: train_loss = 10.980, train_accuracy = 0.990, val_loss = 30.688, val_accuracy = 0.936\n",
      "Epoch 25: train_loss = 8.596, train_accuracy = 0.992, val_loss = 30.402, val_accuracy = 0.935\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 25\n",
    "\n",
    "model = notmnist_model()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    for X, y, label in dataset.train_loader:\n",
    "        X = X.to(device); y = y.to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (torch.argmax(pred, 1) == y).sum()\n",
    "        \n",
    "    train_accuracy = train_accuracy.item() / dataset.train_size\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y, label in dataset.val_loader:\n",
    "            X = X.to(device); y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += (torch.argmax(pred, 1) == y).sum()\n",
    "        \n",
    "    val_accuracy = val_accuracy.item() / dataset.val_size\n",
    "    \n",
    "    print('Epoch %.2d: train_loss = %.3f, train_accuracy = %.3f, val_loss = %.3f, val_accuracy = %.3f' % (\n",
    "        epoch, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = os.path.join('models', 'notmnist.pt')\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.937\n",
      "Test error rate: 0.063\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_accuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y, label in dataset.test_loader:\n",
    "        X = X.to(device); y = y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        test_accuracy += (torch.argmax(pred, 1) == y).sum()\n",
    "\n",
    "test_accuracy = test_accuracy.item() / dataset.test_size\n",
    "\n",
    "print('Test accuracy: %.3f' % test_accuracy)\n",
    "print('Test error rate: %.3f' % (1 - test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
