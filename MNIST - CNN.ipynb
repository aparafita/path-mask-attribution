{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mnist_cnn import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_CUDA = False\n",
    "\n",
    "if not DISABLE_CUDA and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(\n",
    "    os.path.join(*'data/MNIST'.split('/')),\n",
    "    batch_size=32, val_size=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_model():\n",
    "    feature_model = nn.Sequential( # 1, 28, 28\n",
    "        OrderedDict([\n",
    "            ('conv1', nn.Conv2d(1, 16, kernel_size=5, stride=3, padding=2, bias=False)), # 16, 10, 10\n",
    "            ('conv1_bn', nn.BatchNorm2d(16)),\n",
    "            ('conv1_relu', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(16, 32, kernel_size=3, stride=1, bias=False)), # 32, 8, 8\n",
    "            ('conv2_bn', nn.BatchNorm2d(32)),\n",
    "            ('conv2_relu', nn.ReLU()),\n",
    "            ('conv3', nn.Conv2d(32, 64, kernel_size=3, stride=1, bias=False)), # 64, 6, 6\n",
    "            ('conv3_bn', nn.BatchNorm2d(64)),\n",
    "            ('conv3_relu', nn.ReLU())\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    classifier_model = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('dense1', nn.Linear(64 * 6 * 6, 128, bias=False)),\n",
    "            ('dense1_bn', nn.BatchNorm1d(128)),\n",
    "            ('dense1_relu', nn.ReLU()),\n",
    "            ('dense1_dropout', nn.Dropout()),\n",
    "            ('output', nn.Linear(128, 10)),\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        OrderedDict([\n",
    "            ('features', feature_model),\n",
    "            ('flatten', Flatten()),\n",
    "            ('classifier', classifier_model)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train_loss = 322.671, train_accuracy = 0.950, val_loss = 17.679, val_accuracy = 0.987\n",
      "Epoch 02: train_loss = 104.895, train_accuracy = 0.980, val_loss = 14.042, val_accuracy = 0.989\n",
      "Epoch 03: train_loss = 78.465, train_accuracy = 0.984, val_loss = 13.018, val_accuracy = 0.989\n",
      "Epoch 04: train_loss = 62.800, train_accuracy = 0.988, val_loss = 12.603, val_accuracy = 0.991\n",
      "Epoch 05: train_loss = 53.344, train_accuracy = 0.989, val_loss = 10.926, val_accuracy = 0.991\n",
      "Epoch 06: train_loss = 48.640, train_accuracy = 0.990, val_loss = 12.144, val_accuracy = 0.991\n",
      "Epoch 07: train_loss = 40.582, train_accuracy = 0.991, val_loss = 11.432, val_accuracy = 0.991\n",
      "Epoch 08: train_loss = 36.592, train_accuracy = 0.992, val_loss = 10.457, val_accuracy = 0.992\n",
      "Epoch 09: train_loss = 31.947, train_accuracy = 0.993, val_loss = 11.282, val_accuracy = 0.992\n",
      "Epoch 10: train_loss = 31.277, train_accuracy = 0.994, val_loss = 10.243, val_accuracy = 0.992\n",
      "Epoch 11: train_loss = 27.644, train_accuracy = 0.994, val_loss = 12.145, val_accuracy = 0.992\n",
      "Epoch 12: train_loss = 26.617, train_accuracy = 0.994, val_loss = 12.295, val_accuracy = 0.992\n",
      "Epoch 13: train_loss = 19.882, train_accuracy = 0.996, val_loss = 12.101, val_accuracy = 0.992\n",
      "Epoch 14: train_loss = 24.234, train_accuracy = 0.995, val_loss = 11.734, val_accuracy = 0.992\n",
      "Epoch 15: train_loss = 19.407, train_accuracy = 0.996, val_loss = 12.726, val_accuracy = 0.992\n",
      "Epoch 16: train_loss = 18.288, train_accuracy = 0.996, val_loss = 12.292, val_accuracy = 0.992\n",
      "Epoch 17: train_loss = 16.553, train_accuracy = 0.996, val_loss = 12.329, val_accuracy = 0.993\n",
      "Epoch 18: train_loss = 16.186, train_accuracy = 0.997, val_loss = 14.007, val_accuracy = 0.990\n",
      "Epoch 19: train_loss = 17.945, train_accuracy = 0.996, val_loss = 11.592, val_accuracy = 0.993\n",
      "Epoch 20: train_loss = 16.898, train_accuracy = 0.996, val_loss = 12.579, val_accuracy = 0.993\n",
      "Epoch 21: train_loss = 15.860, train_accuracy = 0.997, val_loss = 11.780, val_accuracy = 0.993\n",
      "Epoch 22: train_loss = 12.883, train_accuracy = 0.997, val_loss = 13.261, val_accuracy = 0.993\n",
      "Epoch 23: train_loss = 15.207, train_accuracy = 0.997, val_loss = 14.347, val_accuracy = 0.992\n",
      "Epoch 24: train_loss = 15.465, train_accuracy = 0.997, val_loss = 13.048, val_accuracy = 0.992\n",
      "Epoch 25: train_loss = 13.042, train_accuracy = 0.997, val_loss = 14.758, val_accuracy = 0.991\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 25\n",
    "\n",
    "model = mnist_model()\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    \n",
    "    for X, y, label in dataset.train_loader:\n",
    "        X = X.to(device); y = y.to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(X)\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_accuracy += (torch.argmax(pred, 1) == y).sum()\n",
    "        \n",
    "    train_accuracy = train_accuracy.item() / dataset.train_size\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y, label in dataset.val_loader:\n",
    "            X = X.to(device); y = y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            val_accuracy += (torch.argmax(pred, 1) == y).sum()\n",
    "        \n",
    "    val_accuracy = val_accuracy.item() / dataset.val_size\n",
    "    \n",
    "    print('Epoch %.2d: train_loss = %.3f, train_accuracy = %.3f, val_loss = %.3f, val_accuracy = %.3f' % (\n",
    "        epoch, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = os.path.join('models', 'mnist.pt')\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.993\n",
      "Test error rate: 0.007\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_accuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y, label in dataset.test_loader:\n",
    "        X = X.to(device); y = y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        test_accuracy += (torch.argmax(pred, 1) == y).sum()\n",
    "\n",
    "test_accuracy = test_accuracy.item() / dataset.test_size\n",
    "\n",
    "print('Test accuracy: %.3f' % test_accuracy)\n",
    "print('Test error rate: %.3f' % (1 - test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
